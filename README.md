# state_farm_coding_exercise
To apply for a data science role at State Farm, the insurance company's human resources representative requested that I complete this classification coding exercise as part of the pre-screening process. For this exercise, State Farm supplied me with a dirty training and test data set. What made the data sets dirty were misspelled categories, and missing data values and categories. While both data sets had 99 features, what made them different from one another is the absence of the dependent y variable in the test set. Overall, the exercise's objective is to train machine learning models using the entire training data set and use the models to generate predictions for the test set. To accomplish this objective, I explored and cleaned the training and test sets, selected features for modeling in both data sets, and built logistic regression and decision tree models with the training set. Then, I fed the test set data into those models to calculate the probability of belonging to the positive class, which is labeled as "1." 
